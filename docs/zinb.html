<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2018-03-04 Sun 23:24 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Mean/dispersion estimation</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Mean/dispersion estimation</h1>

<div id="outline-container-orgbddc3b7" class="outline-2">
<h2 id="orgbddc3b7">Introduction</h2>
<div class="outline-text-2" id="text-orgbddc3b7">
<p>
We take a modular approach to call QTLs:
</p>

<ol class="org-ol">
<li>Estimate a mean and a dispersion for each individual</li>
<li>Treat the mean/dispersion as continuous phenotypes and perform QTL mapping</li>
</ol>

<p>
Here, we solve (1).
</p>

<ol class="org-ol">
<li><a href="#org269d03c">We implement GPU-based ML estimation</a></li>
<li><a href="#orgd9318d9">We implement CPU-based ML estimation</a></li>
</ol>
</div>
</div>

<div id="outline-container-orge096f85" class="outline-2">
<h2 id="orge096f85">Model specification</h2>
<div class="outline-text-2" id="text-orge096f85">
<p>
Let \(r_{ijk}\) denote the number of molecules for individual \(i\), cell
\(j\), gene \(k\). Let \(R_{ij}\) denote a size factor for each cell. As a
first pass, define \(R_{ij} = \sum_k r_{ijk}\).
</p>

<p>
Following Hilbe 2012, we derive the negative binomial as a Poisson-Gamma
mixture:
</p>

<p>
\[ r_{ijk} \sim \text{Pois}(R_{ij} \mu_{ik} u_{ijk}) \]
</p>

<p>
\[ u_{ijk} \sim \text{Gamma}(\phi_{ik}^{-1}, \phi_{ik}^{-1}) \]
</p>

<p>
Here, \(\mu_{ik}u_{ijk}\) denotes relative expression
(<a href="https://arxiv.org/abs/1104.3889">Pachter 2011</a>). Marginalizing out \(u\)
yields the negative binomial distribution, with log likelihood:
</p>

<p>
\[ \ln p(r_{ijk} \mid R_{ij}, \mu_{ik}, \phi_{ik}) = r_{ijk} \ln\left(\frac{R_{ij}\mu_{ik}\phi_{ik}}{1 + R_{ij}\mu_{ik}\phi_{ik}}\right) - \phi_{ik}^{-1} \ln(1 + R_{ij}\mu_{ik}\phi_{ik}) + \ln \Gamma(r_{ijk} + \phi_{ik}^{-1}) - \ln \Gamma(r_{ijk} + 1) - \ln \Gamma(\phi^{-1}) \]
</p>

<p>
We have multiple data points (30-200 cells) per mean/dispersion parameter, so
simply minimizing the negative log likelihood should give reasonable
estimates.
</p>

<p>
We can additionally account for zero-inflation, by letting \(\pi_{\cdot}\)
denote the probability of a "technical zero" (i.e., not arising from the
negative-binomial).
</p>

<p>
As a first pass, estimate dropout assuming parameters \(\pi_k\) are shared
across cells (and individuals) for each gene. This assumption allows us to
directly estimate the parameter from the data without requiring
shrinkage/regularization to avoid overfitting.
</p>

<p>
Then, the log-likelihood of the data is:
</p>

<p>
\[ \ln p(r_{ijk} \mid \cdot) = \ln(\pi_\cdot + (1 -  \pi_{\cdot}) p(r_{ijk}
    \mid R_{ij}, \mu_{ik}, \phi_{ik}))\ \text{if}\ r_{ijk} = 0 \]
\[ \ln p(r_{ijk} \mid \cdot) = \ln(1 - \pi_{\cdot}) + \ln p(r_{ijk} \mid
    R_{ij}, \mu_{ik}, \phi_{ik})\ \text{otherwise} \]
</p>
</div>
</div>

<div id="outline-container-org269d03c" class="outline-2">
<h2 id="org269d03c">Tensorflow implementation</h2>
<div class="outline-text-2" id="text-org269d03c">
<p>
We optimize all of the parameters together, using one-hot encoding to map
parameters to data points. This makes inference more amenable to running on
the GPU.
</p>

<p>
Use <code>tensorflow</code> to automatically differentiate the negative log likelihood and
perform gradient descent.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org9a4aea9"><span class="org-keyword">def</span> <span class="org-function-name">sigmoid</span>(x):
  <span class="org-doc">"""Numerically safe sigmoid"""</span>
  <span class="org-keyword">return</span> tf.clip_by_value(tf.sigmoid(x), -13, 13)

<span class="org-keyword">def</span> <span class="org-function-name">log</span>(x):
  <span class="org-doc">"""Numerically safe log"""</span>
  <span class="org-keyword">return</span> tf.log(x + 1e-8)

<span class="org-keyword">def</span> <span class="org-function-name">nb_llik</span>(x, mean, inv_disp):
  <span class="org-doc">"""Log likelihood of x distributed as NB</span>

<span class="org-doc">  See Hilbe 2012, eq. 8.10</span>

<span class="org-doc">  mean - mean (&gt; 0)</span>
<span class="org-doc">  inv_disp - inverse dispersion (&gt; 0)</span>

<span class="org-doc">  """</span>
  <span class="org-keyword">return</span> (x * log(mean / inv_disp) -
          x * log(1 + mean / inv_disp) -
          inv_disp * log(1 + mean / inv_disp) +
          tf.lgamma(x + inv_disp) -
          tf.lgamma(inv_disp) -
          tf.lgamma(x + 1))

<span class="org-keyword">def</span> <span class="org-function-name">zinb_llik</span>(x, mean, inv_disp, logodds, eps=1e-8):
  <span class="org-doc">"""Log likelihood of x distributed as ZINB</span>

<span class="org-doc">  See Hilbe 2012, eq. 11.12, 11.13</span>

<span class="org-doc">  mean - mean (&gt; 0)</span>
<span class="org-doc">  inv_disp - inverse dispersion (&gt; 0)</span>
<span class="org-doc">  logodds - dropout log odds</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">case_zero</span> = log(sigmoid(-logodds) + sigmoid(logodds) * tf.exp(nb_llik(x, mean, inv_disp)))
  <span class="org-variable-name">case_non_zero</span> = -tf.nn.softplus(logodds) + nb_llik(x, mean, inv_disp)
  <span class="org-keyword">return</span> tf.where(tf.less(x, 1e-8), case_zero, case_non_zero)

<span class="org-keyword">def</span> <span class="org-function-name">fit</span>(umi, onehot, size_factor, gene_dropout=<span class="org-constant">False</span>, ind_dropout=<span class="org-constant">False</span>, learning_rate=1e-2, max_epochs=1000):
  <span class="org-doc">"""Return estimated log mean and log dispersion. </span>

<span class="org-doc">  If fitting a zero-inflated model, additionally return dropout log odds.</span>

<span class="org-doc">  umi - count matrix (n x p; float32)</span>
<span class="org-doc">  onehot - mapping of individuals to cells (m x n; float32)</span>
<span class="org-doc">  size_factor - size factor vector (n x 1; float32)</span>
<span class="org-doc">  gene_dropout - fit one dropout parameter per gene</span>
<span class="org-doc">  ind_dropout - fit one dropout parameter per individual</span>
<span class="org-doc">  init_log_mean - initial value for estimated log mean (m x p; float32)</span>
<span class="org-doc">  init_log_disp - initial value for estimated log dispersion (m x p; float32)</span>

<span class="org-doc">  If ind_dropout is True, gene_dropout must be True, otherwise raises</span>
<span class="org-doc">  ArgumentError.</span>

<span class="org-doc">  Returns:</span>

<span class="org-doc">  log_mean - log mean parameter (m x p)</span>
<span class="org-doc">  log_disp - log dispersion parameter (m x p)</span>
<span class="org-doc">  dropout - dropout log odds (1 x p if gene_dropout, n x p if ind_dropout)</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = umi.shape
  <span class="org-variable-name">_</span>, <span class="org-variable-name">m</span> = onehot.shape

  <span class="org-variable-name">params</span> = <span class="org-builtin">locals</span>()
  <span class="org-variable-name">graph</span> = tf.Graph()
  <span class="org-keyword">with</span> graph.as_default(), graph.device(<span class="org-string">'/gpu:*'</span>):
    <span class="org-variable-name">size_factor</span> = tf.Variable(size_factor, trainable=<span class="org-constant">False</span>)
    <span class="org-variable-name">umi</span> = tf.Variable(umi, trainable=<span class="org-constant">False</span>)
    <span class="org-variable-name">onehot</span> = tf.Variable(onehot, trainable=<span class="org-constant">False</span>)

    <span class="org-variable-name">mean</span> = tf.exp(tf.Variable(tf.zeros([m, p])))
    <span class="org-variable-name">inv_disp</span> = tf.exp(tf.Variable(tf.zeros([m, p])))

    <span class="org-keyword">if</span> gene_dropout:
      <span class="org-keyword">if</span> ind_dropout:
        <span class="org-variable-name">dropout_params</span> = tf.Variable(tf.zeros([m, p]))
        <span class="org-variable-name">dropout</span> = tf.matmul(onehot, dropout_params)
      <span class="org-keyword">else</span>:
        <span class="org-variable-name">dropout_params</span> = tf.Variable(tf.zeros([1, p]))
        <span class="org-variable-name">dropout</span> = dropout_params
      <span class="org-variable-name">llik</span> = tf.reduce_mean(
        zinb_llik(umi, size_factor * tf.matmul(onehot, mean),
                  tf.matmul(onehot, inv_disp), dropout))
    <span class="org-keyword">elif</span> ind_dropout:
      <span class="org-keyword">raise</span> <span class="org-type">ValueError</span>(<span class="org-string">'Cannot specify individual-specific dropout without gene-specific dropout'</span>)
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">llik</span> = tf.reduce_mean(
        nb_llik(umi, size_factor * tf.matmul(onehot, mean),
                tf.matmul(onehot, inv_disp)))

    <span class="org-variable-name">train</span> = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-llik)
    <span class="org-variable-name">opt</span> = [tf.log(mean), -tf.log(inv_disp)]
    <span class="org-keyword">if</span> gene_dropout:
      opt.append(dropout_params)
    <span class="org-variable-name">curr</span> = <span class="org-builtin">float</span>(<span class="org-string">'-inf'</span>)
    <span class="org-keyword">with</span> tf.Session() <span class="org-keyword">as</span> sess:
      sess.run(tf.global_variables_initializer())
      <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(max_epochs):
        <span class="org-variable-name">_</span>, <span class="org-variable-name">update</span> = sess.run([train, llik])
        <span class="org-keyword">if</span> <span class="org-keyword">not</span> np.isfinite(update):
          <span class="org-keyword">raise</span> tf.train.NanLossDuringTrainingError
        <span class="org-keyword">if</span> <span class="org-keyword">not</span> i % 100:
          <span class="org-keyword">print</span>(i, update)
      <span class="org-keyword">return</span> sess.run(opt)
</pre>
</div>
</div>

<div id="outline-container-orge3a2968" class="outline-3">
<h3 id="orge3a2968">Quantile-quantile diagnostic plot</h3>
<div class="outline-text-3" id="text-orge3a2968">
<p>
The challenge in visualizing the fitted distributions is that the
observations \(r_{ijk}\) are not drawn iid. from a distribution
\(g_{ik}(\cdot)\). 
</p>

<p>
Instead, we have \(r_{ijk} \sim g_{ijk}(\cdot)\), and we have used maximum
likelihood to estimate distributions \(\hat{g}_{ijk}\).
</p>

<p>
We can use the probability integral transform to develop a diagnostic (as in
<code>ashr</code>): Let \(\hat{G}_{ijk}\) denote the CDF of \(\hat{g}_{ijk}\). Then, the
distribution of values \(\hat{G}_{ijk}(r_{ijk})\) should be uniform.
</p>

<p>
In the case of modeling dropout, the CDF is discontinuous due to the point
mass on zero, which we can observe using a point-normal mixture:
</p>

<p>
\[ x \sim \pi \delta(x) + (1 - \pi) N(0, 1) \]
</p>

<p>
\[ \Pr(X < x) = \pi 1_{x > 0} + (1 - \pi) \Phi(x) \]
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">N</span> = 1000
<span class="org-variable-name">G</span> = st.norm()
<span class="org-variable-name">observations</span> = G.rvs(size=N) * (np.random.uniform(size=N) &lt; 0.5)
<span class="org-variable-name">quantiles</span> = .5 * (observations &gt; 0) + .5 * G.cdf(observations)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.hist(quantiles, bins=50, color=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Estimated quantile'</span>)
<span class="org-variable-name">_</span> = plt.ylabel(<span class="org-string">'Number of observations'</span>)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/point-normal-cdf.png" alt="point-normal-cdf.png">
</p>
</div>

<p>
In this case, we can instead compute a randomized quantile, which will be
uniform in expectation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rand_quantiles</span> = G.cdf(observations) + np.random.uniform(size=N) * np.isclose(observations, 0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.hist(rand_quantiles, color=<span class="org-string">'k'</span>, bins=50)
plt.xlabel(<span class="org-string">'Estimated quantile'</span>)
<span class="org-variable-name">_</span> = plt.ylabel(<span class="org-string">'Number of observations'</span>)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/point-normal-diagnostic.png" alt="point-normal-diagnostic.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">estimated_cdf</span>(x, mean, disp, size, onehot, gene_dropout=<span class="org-constant">None</span>, ind_dropout=<span class="org-constant">None</span>):
  <span class="org-variable-name">n</span> = onehot.dot(np.exp(-disp.values.T) + 1e-8)
  <span class="org-variable-name">p</span> = 1 / (1 + size.to_frame().values * onehot.dot(np.exp(mean.values + disp.values).T))
  <span class="org-keyword">assert</span> (n.values &gt; 0).<span class="org-builtin">all</span>()
  <span class="org-keyword">assert</span> (p.values &gt;= 0).<span class="org-builtin">all</span>()
  <span class="org-keyword">assert</span> (p.values &lt;= 1).<span class="org-builtin">all</span>()
  <span class="org-variable-name">G</span> = st.nbinom(n=n, p=p).cdf(x)
  <span class="org-keyword">if</span> gene_dropout <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">G</span> *= sp.expit(-gene_dropout.values.T)
    <span class="org-variable-name">G</span> += sp.expit(gene_dropout.values.T)
  <span class="org-keyword">elif</span> ind_dropout <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">G</span> *= onehot.dot(sp.expit(-ind_dropout.values.T))
    <span class="org-variable-name">G</span> += onehot.dot(sp.expit(ind_dropout.values.T))
  <span class="org-keyword">assert</span> (G &lt;= 1).<span class="org-builtin">all</span>()
  <span class="org-keyword">return</span> G

<span class="org-keyword">def</span> <span class="org-function-name">diagnostic</span>(umi, mean, disp, size, onehot, **kwargs):
  <span class="org-variable-name">q</span> = estimated_cdf(umi.values.T, mean, disp, size, onehot, **kwargs)
  plt.clf()
  plt.scatter(x=np.linspace(0, 1, q.shape[0]),
              y=<span class="org-builtin">sorted</span>(q.ravel()),
              s=0.5)
  plt.plot([[0, 0], [1, 1]], c=<span class="org-string">'black'</span>)
  plt.title(umi.index[0])
  plt.xlabel(<span class="org-string">'Expected quantile'</span>)
  plt.ylabel(<span class="org-string">'Estimated quantile'</span>)
</pre>
</div>

<p>
Look at the quantiles of the QQ plots over all genes:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">diagnostic_quantiles</span>(umi, mean, disp, size, onehot, quantiles=<span class="org-constant">None</span>, **kwargs):
  <span class="org-keyword">if</span> quantiles <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">quantiles</span> = np.array([.05, .25, .5, .75, .95])
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">quantiles</span> = np.array(quantiles)
    <span class="org-keyword">assert</span> (0 &lt;= quantiles &lt;= 1).<span class="org-builtin">all</span>()
  <span class="org-variable-name">cdf</span> = np.sort(estimated_cdf(umi.values.T, mean, disp, size, onehot, **kwargs).T)
  <span class="org-variable-name">cdf_quantiles</span> = np.percentile(cdf, 100 * quantiles, interpolation=<span class="org-string">'higher'</span>, axis=0)

  plt.clf()
  <span class="org-keyword">for</span> q, row <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(quantiles, cdf_quantiles):
    plt.scatter(x=np.linspace(0, 1, row.shape[0]), y=row, c=colorcet.cm[<span class="org-string">'kbc'</span>](q), s=.5, label=q)
  plt.plot([0, 1], [0, 1], c=<span class="org-string">'r'</span>, ls=<span class="org-string">'dashed'</span>)
  plt.legend()
  plt.xlabel(<span class="org-string">'Expected quantile'</span>)
  plt.ylabel(<span class="org-string">'Estimated quantile'</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-orga83ce40" class="outline-3">
<h3 id="orga83ce40">Read the data</h3>
<div class="outline-text-3" id="text-orga83ce40">
<p>
Read the QC'ed data.
</p>

<p>
Onehot-encode the samples.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org9e8be09"><span class="org-variable-name">individuals</span> = <span class="org-builtin">sorted</span>(annotations[<span class="org-string">'chip_id'</span>].unique())
<span class="org-variable-name">onehot</span> = np.zeros((umi.shape[1], <span class="org-builtin">len</span>(individuals)), dtype=np.float32)
onehot[np.arange(onehot.shape[0]),annotations[<span class="org-string">'chip_id'</span>].<span class="org-builtin">apply</span>(<span class="org-keyword">lambda</span> x: individuals.index(x))] = 1
<span class="org-variable-name">onehot</span> = pd.DataFrame(onehot, columns=individuals, index=umi.columns)
onehot.shape
</pre>
</div>

<pre class="example">
(4995, 54)

</pre>

<p>
Check that one-hot encoding is OK:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">for</span> _ <span class="org-keyword">in</span> <span class="org-builtin">range</span>(100):
  <span class="org-variable-name">gene</span> = np.random.choice(umi.index)
  <span class="org-variable-name">ind</span> = np.random.choice(individuals)
  <span class="org-variable-name">idx</span> = individuals.index(ind)
  <span class="org-keyword">assert</span> (umi.loc[gene, (annotations[<span class="org-string">'chip_id'</span>] == ind).values] == 
          umi.loc[gene, onehot.dot(np.eye(onehot.shape[1])[idx]).astype(<span class="org-builtin">bool</span>)]).<span class="org-builtin">all</span>()
</pre>
</div>
</div>
</div>

<div id="outline-container-org1429fd2" class="outline-3">
<h3 id="org1429fd2">Fit NB</h3>
<div class="outline-text-3" id="text-org1429fd2">
<p>
Estimate means and dispersions assuming no dropout.
</p>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;zinb-imports&gt;&gt;
&lt;&lt;tf-imports&gt;&gt;
&lt;&lt;zinb-impl&gt;&gt;
&lt;&lt;read-data-qc&gt;&gt;
&lt;&lt;onehot-qc&gt;&gt;
<span class="org-variable-name">mean</span>, <span class="org-variable-name">dispersion</span> = fit(
  umi=umi.values.T.astype(np.float32),
  onehot=onehot.values.astype(np.float32),
  size_factor=umi.agg(np.<span class="org-builtin">sum</span>).astype(np.float32).values.reshape(-1, 1),
  learning_rate=1e-2,
  max_epochs=8000)
pd.DataFrame(mean.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/mean2.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
pd.DataFrame(dispersion.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/dispersion2.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
</pre>
</div>

<p>
Check the goodness of fit.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">mean</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/mean2.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
<span class="org-variable-name">disp</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/dispersion2.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">diagnostic(umi.iloc[:1], mean.iloc[:1], disp.iloc[:1], size, onehot)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/nb-quantiles.png" alt="nb-quantiles.png">
</p>
</div>

<p>
The estimated quantiles are higher than the expected quantiles, suggesting
that the estimated distributions have too much density at lower values. This
result is explained by the fact that means are biased downwards and
dispersions are biased upwards due to zero-inflation. Accordingly, we expect
to find some genes which depart even more from uniform quantiles.
</p>

<div class="org-src-container">
<pre class="src src-ipython">diagnostic_quantiles(umi, mean, disp, size, onehot)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/nb-quantiles-dist.png" alt="nb-quantiles-dist.png">
</p>
</div>
</div>
</div>

<div id="outline-container-orga8ab6f4" class="outline-3">
<h3 id="orga8ab6f4">Fit ZINB</h3>
<div class="outline-text-3" id="text-orga8ab6f4">
<p>
Estimate the parameters of the zero-inflated model assuming dropout per gene.
</p>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;zinb-imports&gt;&gt;
&lt;&lt;tf-imports&gt;&gt;
&lt;&lt;zinb-impl&gt;&gt;
&lt;&lt;read-data-qc&gt;&gt;
&lt;&lt;onehot-qc&gt;&gt;
<span class="org-variable-name">mean</span>, <span class="org-variable-name">dispersion</span>, <span class="org-variable-name">dropout</span> = fit(
  umi=umi.values.T.astype(np.float32),
  onehot=onehot.values.astype(np.float32),
  size_factor=umi.agg(np.<span class="org-builtin">sum</span>).astype(np.float32).values.reshape(-1, 1),
  gene_dropout=<span class="org-constant">True</span>,
  learning_rate=1e-2,
  max_epochs=8000)
pd.DataFrame(mean.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-mean.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
pd.DataFrame(dispersion.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-dispersion.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
pd.DataFrame(dropout.T, index=umi.index).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-dropout.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
</pre>
</div>

<p>
Plot the diagnostic for the model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">zi_mean</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-mean.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
<span class="org-variable-name">zi_disp</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-dispersion.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
<span class="org-variable-name">zi_dropout</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi-dropout.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">diagnostic_quantiles(umi, zi_mean, zi_disp, size, onehot, gene_dropout=zi_dropout)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/zinb-diagnostic.png" alt="zinb-diagnostic.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org1986c5b" class="outline-3">
<h3 id="org1986c5b">Fit ZINB2</h3>
<div class="outline-text-3" id="text-org1986c5b">
<p>
Estimate the parameters of the zero-inflated model assuming dropout per
individual and gene.
</p>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;zinb-imports&gt;&gt;
&lt;&lt;tf-imports&gt;&gt;
&lt;&lt;zinb-impl&gt;&gt;
&lt;&lt;read-data-qc&gt;&gt;
&lt;&lt;onehot-qc&gt;&gt;
<span class="org-variable-name">mean</span>, <span class="org-variable-name">dispersion</span>, <span class="org-variable-name">dropout</span> = fit(
  umi=umi.values.T.astype(np.float32),
  onehot=onehot.values.astype(np.float32),
  size_factor=umi.agg(np.<span class="org-builtin">sum</span>).astype(np.float32).values.reshape(-1, 1),
  gene_dropout=<span class="org-constant">True</span>,
  ind_dropout=<span class="org-constant">True</span>,
  learning_rate=1e-2,
  max_epochs=8000)
pd.DataFrame(mean.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-mean.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
pd.DataFrame(dispersion.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-dispersion.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
pd.DataFrame(dropout.T, index=umi.index, columns=onehot.columns).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-dropout.txt.gz'</span>, sep=<span class="org-string">' '</span>, compression=<span class="org-string">'gzip'</span>)
</pre>
</div>

<p>
Plot the data and fitted distribution.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">zi2_mean</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-mean.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
<span class="org-variable-name">zi2_disp</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-dispersion.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
<span class="org-variable-name">zi2_dropout</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/zi2-dropout.txt.gz'</span>, sep=<span class="org-string">' '</span>, index_col=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">diagnostic_quantiles(umi, zi2_mean, zi2_disp, size, onehot, ind_dropout=zi2_dropout)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/zinb2-diagnostic.png" alt="zinb2-diagnostic.png">
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd9318d9" class="outline-2">
<h2 id="orgd9318d9">numpy/scipy implementation</h2>
<div class="outline-text-2" id="text-orgd9318d9">
<p>
Optimize the negative log-likelihood.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org9a58076"><span class="org-keyword">import</span> scipy.optimize <span class="org-keyword">as</span> so

<span class="org-keyword">def</span> <span class="org-function-name">log</span>(x):
  <span class="org-doc">"""Numerically safe log"""</span>
  <span class="org-keyword">return</span> np.log(x + 1e-8)

<span class="org-keyword">def</span> <span class="org-function-name">sigmoid</span>(x):
  <span class="org-doc">"""Numerically safe sigmoid"""</span>
  <span class="org-variable-name">lim</span> = np.log(np.finfo(np.float64).resolution)
  <span class="org-keyword">return</span> np.clip(sp.expit(x), lim, -lim)

<span class="org-keyword">def</span> <span class="org-function-name">zinb</span>(theta, x, size):
  <span class="org-variable-name">theta</span>, <span class="org-variable-name">dropout</span> = theta[:2], sigmoid(theta[2])
  <span class="org-variable-name">case_zero</span> = log(dropout + (1 - dropout) * np.exp(-nb(theta, x, size)))
  <span class="org-variable-name">case_non_zero</span> = log(1 - dropout) - nb(theta, x, size)
  <span class="org-keyword">return</span> -np.where(x &lt; 1e-8, case_zero, case_non_zero).mean()

<span class="org-keyword">def</span> <span class="org-function-name">nb</span>(theta, x, size):
  <span class="org-variable-name">mean</span>, <span class="org-variable-name">inv_disp</span> = np.exp(theta)
  <span class="org-variable-name">mean</span> *= size
  <span class="org-keyword">assert</span> mean.shape == x.shape
  <span class="org-keyword">return</span> -(x * log(mean / inv_disp) -
           x * log(1 + mean / inv_disp) -
           inv_disp * log(1 + mean / inv_disp) +
           sp.gammaln(x + inv_disp) -
           sp.gammaln(inv_disp) -
           sp.gammaln(x + 1)).mean()
</pre>
</div>

<p>
Use this to check the parameter estimation for a particular gene/individual.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">extract_data</span>(ind, gene):
  <span class="org-keyword">with</span> sqlite3.connect(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/browser.db'</span>) <span class="org-keyword">as</span> conn:
    <span class="org-variable-name">umi</span> = pd.read_sql(<span class="org-string">"""select umi.value, annotation.size from umi, annotation </span>
<span class="org-string">    where annotation.chip_id == ? and gene == ? and </span>
<span class="org-string">    umi.sample == annotation.sample;"""</span>, con=conn, params=(ind, gene))
    <span class="org-keyword">return</span> umi
</pre>
</div>

<p>
Shard the data to parallelize over nodes.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> sqlite3.connect(<span class="org-string">'/home/aksarkar/projects/singlecell-qtl/browser/browser.db'</span>) <span class="org-keyword">as</span> conn:
  <span class="org-variable-name">annotation</span> = pd.read_sql(<span class="org-string">'select * from annotation'</span>, con=conn).set_index(<span class="org-string">'sample'</span>)

<span class="org-variable-name">keep_samples</span> = pd.read_table(<span class="org-string">'/home/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">keep_genes</span> = pd.read_table(<span class="org-string">'/home/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">keep_genes</span> = keep_genes[keep_genes.values].index
<span class="org-variable-name">i</span> = 0
<span class="org-keyword">for</span> chunk <span class="org-keyword">in</span> pd.read_table(<span class="org-string">'/home/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz'</span>, index_col=0, chunksize=1000):
  <span class="org-keyword">print</span>(<span class="org-string">'Processing chunk {}'</span>.<span class="org-builtin">format</span>(i))
  <span class="org-variable-name">chunk</span> = (chunk
           .loc[:,keep_samples.values.ravel()]
           .<span class="org-builtin">filter</span>(items=keep_genes, axis=<span class="org-string">'index'</span>))
  <span class="org-keyword">if</span> <span class="org-keyword">not</span> chunk.empty:
    <span class="org-variable-name">chunk</span> = (chunk
             .reset_index()
             .melt(id_vars=<span class="org-string">'gene'</span>, var_name=<span class="org-string">'sample'</span>)
             .merge(annotation, left_on=<span class="org-string">'sample'</span>, right_index=<span class="org-constant">True</span>)
             .sort_values([<span class="org-string">'gene'</span>, <span class="org-string">'chip_id'</span>, <span class="org-string">'sample'</span>]))
    chunk.to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/chunk-{}.txt.gz'</span>.<span class="org-builtin">format</span>(i), compression=<span class="org-string">'gzip'</span>, sep=<span class="org-string">'\t'</span>)
    <span class="org-variable-name">i</span> += 1
</pre>
</div>

<p>
Process each chunk in parallel.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org14a4f03"><span class="org-keyword">def</span> <span class="org-function-name">fit_gene</span>(chunk):
  <span class="org-variable-name">res0</span> = so.minimize(nb, x0=[0, 0], args=(chunk[:,0], chunk[:,1]))
  <span class="org-variable-name">pi0</span> = (chunk[:,0] == 0).<span class="org-builtin">sum</span>() / chunk.shape[0] + 1e-8
  <span class="org-variable-name">res</span> = so.minimize(zinb, x0=<span class="org-builtin">list</span>(res0.x) + [sp.logit(pi0 + 1e-8)], args=(chunk[:,0], chunk[:,1]))
  <span class="org-keyword">return</span> <span class="org-builtin">list</span>(res0.x) + [res0.fun, res0.success] + <span class="org-builtin">list</span>(res.x) + [res.fun, res.success]

<span class="org-keyword">def</span> <span class="org-function-name">compute_breaks</span>(chunk, by_ind=<span class="org-constant">False</span>):
  <span class="org-comment-delimiter"># </span><span class="org-comment">Each subproblem has fixed size, so we can just split on integer indices</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">(instead of grouping)</span>
  <span class="org-variable-name">num_genes</span> = <span class="org-builtin">len</span>(<span class="org-builtin">set</span>(chunk[<span class="org-string">'gene'</span>]))
  <span class="org-variable-name">num_samples</span> = <span class="org-builtin">len</span>(<span class="org-builtin">set</span>(chunk[<span class="org-string">'sample'</span>]))
  <span class="org-variable-name">breaks</span> = num_samples * np.arange(num_genes).reshape(-1, 1)
  <span class="org-keyword">if</span> by_ind:
    <span class="org-variable-name">num_samples_per_ind</span> = chunk.iloc[:num_samples][<span class="org-string">'chip_id'</span>].value_counts().sort_index().values
    <span class="org-variable-name">breaks</span> += np.cumsum(num_samples_per_ind).reshape(1, -1)
  <span class="org-keyword">else</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">We need to get the right end point of each subproblem (exclusive)</span>
    <span class="org-variable-name">breaks</span> += num_samples
  <span class="org-keyword">return</span> breaks.ravel()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;zinb-imports&gt;&gt;
<span class="org-keyword">import</span> argparse
<span class="org-keyword">import</span> gzip
<span class="org-keyword">import</span> os
<span class="org-keyword">import</span> multiprocessing <span class="org-keyword">as</span> mp
<span class="org-keyword">import</span> sqlite3
&lt;&lt;np-zinb-impl&gt;&gt;
&lt;&lt;process-chunk-impl&gt;&gt;

<span class="org-variable-name">parser</span> = argparse.ArgumentParser()
parser.add_argument(<span class="org-string">'-g'</span>, <span class="org-string">'--by-gene'</span>, action=<span class="org-string">'store_true'</span>, <span class="org-builtin">help</span>=<span class="org-string">'Estimate one model per gene'</span>, default=<span class="org-constant">False</span>)
<span class="org-variable-name">args</span> = parser.parse_args()

<span class="org-keyword">with</span> mp.Pool() <span class="org-keyword">as</span> pool:
  <span class="org-variable-name">chunk</span> = pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/chunk-{}.txt.gz'</span>.<span class="org-builtin">format</span>(os.getenv(<span class="org-string">'SLURM_ARRAY_TASK_ID'</span>)))
  <span class="org-variable-name">breaks</span> = compute_breaks(chunk, <span class="org-keyword">not</span> args.by_gene)
  <span class="org-variable-name">res</span> = pool.<span class="org-builtin">map</span>(fit_gene, np.split(chunk[[<span class="org-string">'value'</span>, <span class="org-string">'size'</span>]].values, breaks[:-1]))

<span class="org-keyword">with</span> gzip.<span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/result-{}.txt.gz'</span>.<span class="org-builtin">format</span>(os.getenv(<span class="org-string">'SLURM_ARRAY_TASK_ID'</span>)), <span class="org-string">'wt'</span>) <span class="org-keyword">as</span> f:
  <span class="org-keyword">for</span> b <span class="org-keyword">in</span> breaks:
    <span class="org-variable-name">gene</span>, <span class="org-variable-name">ind</span> = chunk.iloc[b - 1][[<span class="org-string">'gene'</span>, <span class="org-string">'chip_id'</span>]]
    <span class="org-keyword">print</span>(gene, ind, *res.pop(0), <span class="org-builtin">file</span>=f)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl --job-name=<span class="org-string">"np-zinb"</span> --mem=4G -a 0-20 -n1 -c28 --exclusive
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate scqtl
python /scratch/midway2/aksarkar/singlecell/np-zinb.py -g
</pre>
</div>

<p>
Populate the database.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> sqlite3.connect(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/browser.db'</span>) <span class="org-keyword">as</span> conn:
  conn.execute(<span class="org-string">'drop table if exists params;'</span>)
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(20):
    <span class="org-keyword">for</span> chunk <span class="org-keyword">in</span> pd.read_table(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/result-{}.txt.gz'</span>.<span class="org-builtin">format</span>(i), sep=<span class="org-string">' '</span>, header=<span class="org-constant">None</span>, chunksize=1000):
      <span class="org-variable-name">chunk.columns</span> = [<span class="org-string">'gene'</span>, <span class="org-string">'ind'</span>, <span class="org-string">'nb_log_mean'</span>, <span class="org-string">'nb_log_disp'</span>, <span class="org-string">'nb_nll'</span>, <span class="org-string">'nb_success'</span>, <span class="org-string">'zinb2_log_mean'</span>, <span class="org-string">'zinb2_log_disp'</span>, <span class="org-string">'zinb2_logodds'</span>, <span class="org-string">'zinb_nll'</span>, <span class="org-string">'zinb_success'</span>]
      chunk.to_sql(name=<span class="org-string">'params'</span>, con=conn, index=<span class="org-constant">False</span>, if_exists=<span class="org-string">'append'</span>)
  conn.execute(<span class="org-string">'create index ix_params on params(gene, ind);'</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org322904a" class="outline-2">
<h2 id="org322904a">Noisy gene identification</h2>
<div class="outline-text-2" id="text-org322904a">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">params</span> = pd.read_table(<span class="org-string">'/home/aksarkar/projects/singlecell-qtl/data/params-by-gene.txt.gz'</span>, sep=<span class="org-string">' '</span>, header=<span class="org-constant">None</span>, index_col=0)
<span class="org-variable-name">params.columns</span> = [<span class="org-string">'_'</span>, <span class="org-string">'nb_log_mean'</span>, <span class="org-string">'nb_log_disp'</span>, <span class="org-string">'nb_nll'</span>, <span class="org-string">'nb_success'</span>,
                  <span class="org-string">'zinb2_log_mean'</span>, <span class="org-string">'zinb2_log_disp'</span>, <span class="org-string">'zinb2_logodds'</span>, <span class="org-string">'zinb_nll'</span>,
                  <span class="org-string">'zinb_success'</span>]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">mle</span> = pd.DataFrame({<span class="org-string">'log_mean'</span>: np.where(params[<span class="org-string">'nb_nll'</span>] &lt; params[<span class="org-string">'zinb_nll'</span>], params[<span class="org-string">'nb_log_mean'</span>], params[<span class="org-string">'zinb2_log_mean'</span>]),
                    <span class="org-string">'log_disp'</span>: np.where(params[<span class="org-string">'nb_nll'</span>] &lt; params[<span class="org-string">'zinb_nll'</span>], params[<span class="org-string">'nb_log_disp'</span>], params[<span class="org-string">'zinb2_log_disp'</span>])},
                   index=params.index)
<span class="org-variable-name">mle</span>[<span class="org-string">'mean'</span>] = np.exp(mle[<span class="org-string">'log_mean'</span>])
<span class="org-variable-name">mle</span>[<span class="org-string">'var'</span>] = np.exp(mle[<span class="org-string">'log_mean'</span>]) + np.exp(2 * mle[<span class="org-string">'log_mean'</span>] + mle[<span class="org-string">'log_disp'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.hist(mle[<span class="org-string">'log_disp'</span>], bins=100)
plt.xlabel(<span class="org-string">'Estimated log dispersion'</span>)
plt.ylabel(<span class="org-string">'Number of genes'</span>)
</pre>
</div>

<pre class="example">
Text(0,0.5,'Number of genes')

</pre>

<div class="figure">
<p><img src="figure/zinb.org/disp-dist.png" alt="disp-dist.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.hist(mle[<span class="org-string">'var'</span>], bins=100)
plt.xlabel(<span class="org-string">'Estimated variance'</span>)
plt.ylabel(<span class="org-string">'Number of genes'</span>)
</pre>
</div>

<pre class="example">
Text(0,0.5,'Number of genes')

</pre>

<div class="figure">
<p><img src="figure/zinb.org/var-dist.png" alt="var-dist.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.scatter(x=mle[<span class="org-string">'log_mean'</span>], y=mle[<span class="org-string">'var'</span>] - mle[<span class="org-string">'mean'</span>], s=2, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Estimated log mean expression'</span>)
<span class="org-variable-name">_</span> = plt.ylabel(<span class="org-string">'variance - mean'</span>)
</pre>
</div>


<div class="figure">
<p><img src="figure/zinb.org/noisy-genes.png" alt="noisy-genes.png">
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2018-03-04 Sun 23:24</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
