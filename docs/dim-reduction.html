<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2018-05-29 Tue 15:05 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Dimensionality reduction</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Dimensionality reduction</h1>

<div id="outline-container-orgfbae870" class="outline-2">
<h2 id="orgfbae870">Introduction</h2>
<div class="outline-text-2" id="text-orgfbae870">
<p>
The fundamental inference task is to infer \(p(z_i \mid x_i)\), where \(x_i\)
is a \(p\)-dimensional observation, \(z_i\) is a \(k\)-dimensional latent
variable, and \(k \ll n\).
</p>

<p>
Why do we want to do this?
</p>

<ul class="org-ul">
<li>determine how much variation in the data is explained by known technical
factors</li>
<li>decide whether, and how to remove that variation before trying to explain
the data using biological covariates</li>
</ul>

<p>
Importantly, these analyses are not directly usable for confounder correction
for QTL mapping. Instead, we first need to <a href="zinb.html">learn the underlying distributions
of the data</a> and then perform dimensionality reduction on those
parameters. However, it will be important to consider what data went into
learning those distributions, and how to incorporate known and inferred
confounders into that estimation procedure.
</p>

<p>
Here, we perform the following analyses:
</p>

<ol class="org-ol">
<li><a href="#orgee007e3">We perform PCA on the post-QC data</a> and show that most variation is
explained by gene detection rate</li>
<li><a href="#org7a286e5">We confirm in the real data</a> that the entire distribution of non-zero gene
expression is correlated with gene detection rate</li>
<li><a href="#orgbdbc407">We show that regressing out the percentiles of gene expression</a> eliminates
the dependence on gene detection rate</li>
</ol>
</div>
</div>

<div id="outline-container-orgc2fd770" class="outline-2">
<h2 id="orgc2fd770">Read the data</h2>
<div class="outline-text-2" id="text-orgc2fd770">
<p>
Read the full data matrix and apply the QC filters.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org4cc1779"><span class="org-variable-name">umi</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz'</span>, index_col=0)
<span class="org-variable-name">annotations</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt'</span>)
<span class="org-variable-name">keep_samples</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">keep_genes</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">umi</span> = umi.loc[keep_genes.values.ravel(),keep_samples.values.ravel()]
<span class="org-variable-name">annotations</span> = annotations.loc[keep_samples.values.ravel()]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">umi.shape
</pre>
</div>

<pre class="example">
(10099, 5566)

</pre>
</div>
</div>

<div id="outline-container-orgee007e3" class="outline-2">
<h2 id="orgee007e3">Principal components analysis</h2>
<div class="outline-text-2" id="text-orgee007e3">
<p>
Use PPCA (<a href="http://www.miketipping.com/papers/met-mppca.pdf">Tipping et al 1999</a>) to incorporate gene-specific mean
expression. Use the <code>edgeR</code> pseudocount.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orga4cd765"><span class="org-variable-name">libsize</span> = annotations[<span class="org-string">'mol_hs'</span>].values
<span class="org-variable-name">pseudocount</span> = .5 * libsize / libsize.mean()
<span class="org-variable-name">log_cpm</span> = (np.log(umi + pseudocount) - np.log(libsize + 2 * pseudocount) + 6 * np.log(10)) / np.log(2)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">ppca</span> = skd.PCA(n_components=10)
<span class="org-variable-name">loadings</span> = ppca.fit_transform(log_cpm.values.T)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2)
fig.set_size_inches(8, 8)
<span class="org-variable-name">N</span> = <span class="org-builtin">len</span>(<span class="org-builtin">set</span>(annotations[<span class="org-string">'batch'</span>]))
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(2):
  <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(i, 2):
    <span class="org-keyword">for</span> k, batch <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">sorted</span>(<span class="org-builtin">set</span>(annotations[<span class="org-string">'batch'</span>]))):
      ax[i][j].scatter(loadings[annotations[<span class="org-string">'batch'</span>] == batch,i], loadings[annotations[<span class="org-string">'batch'</span>] == batch,j + 1], c=colorcet.cm[<span class="org-string">'rainbow'</span>](k / N), s=4, marker=<span class="org-string">'+'</span>, alpha=0.5)
      ax[i][j].set_xlabel(<span class="org-string">'PC{}'</span>.<span class="org-builtin">format</span>(j + 2))
      ax[i][j].set_ylabel(<span class="org-string">'PC{}'</span>.<span class="org-builtin">format</span>(i + 1))
ax[1, 0].set_axis_off()
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/dim-reduction.org/pca.png" alt="pca.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2)
fig.set_size_inches(8, 8)
<span class="org-variable-name">N</span> = <span class="org-builtin">len</span>(<span class="org-builtin">set</span>(annotations[<span class="org-string">'batch'</span>]))
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(2):
  <span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(i, 2):
    <span class="org-keyword">for</span> k, batch <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">sorted</span>(<span class="org-builtin">set</span>(annotations[<span class="org-string">'batch'</span>]))):
      ax[i][j].scatter(loadings[annotations[<span class="org-string">'batch'</span>] == batch,i], loadings[annotations[<span class="org-string">'batch'</span>] == batch,j + 1], c=colorcet.cm[<span class="org-string">'rainbow'</span>](k / N), s=4, marker=<span class="org-string">'+'</span>, alpha=0.5)
      ax[i][j].set_xlabel(<span class="org-string">'PC{}'</span>.<span class="org-builtin">format</span>(j + 2))
      ax[i][j].set_ylabel(<span class="org-string">'PC{}'</span>.<span class="org-builtin">format</span>(i + 1))
ax[1, 0].set_axis_off()
fig.tight_layout()
plt.savefig(<span class="org-string">'pca.pdf'</span>)
</pre>
</div>

<pre class="example">
&lt;matplotlib.figure.Figure at 0x7f55719c3e10&gt;

</pre>

<p>
Correlate PCs with known continuous covariates by computing squared Pearson
correlation.
</p>

<p>
Correlating PCs with individual (or other discrete covariates) is non-obvious
because it is a categorical variable, and simply recoding it as integer is
sensitive to ordering. Instead, regress the loading of each cell on each
principal component \(l_{ij}\) against indicator variables for each
individual \(X_{ik}\).
</p>

<p>
\[ l_{ij} = \sum_j X_{ik} \beta_{jk} + \mu + \epsilon \]
</p>

<p>
From the regression fit, we can compute the coefficient of determination
\(R^2\) for each PC \(j\):
</p>

<p>
\[ 1 - \frac{l_j - X \hat{\beta}_j}{l_j - \bar{l_j}} \]
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org7b2d3c5"><span class="org-keyword">def</span> <span class="org-function-name">extract_covars</span>(annotations):
  <span class="org-keyword">return</span> pd.Series({
    <span class="org-string">'Reads'</span>: annotations[<span class="org-string">'umi'</span>],
    <span class="org-string">'Molecules'</span>: annotations[<span class="org-string">'molecules'</span>],
    <span class="org-string">'Mapped %'</span>: annotations[<span class="org-string">'umi'</span>] / annotations[<span class="org-string">'mapped'</span>],
    <span class="org-string">'Genes detected'</span>: annotations[<span class="org-string">'detect_hs'</span>],
  })

<span class="org-keyword">def</span> <span class="org-function-name">correlation</span>(pcs, cont_covars):
  <span class="org-doc">"""Return squared correlation between principal components and covariates</span>

<span class="org-doc">  pcs - DataFrame (n x k)</span>
<span class="org-doc">  cont_covars - DataFrame (n x q)</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> pcs:
    <span class="org-keyword">for</span> j <span class="org-keyword">in</span> cont_covars:
      <span class="org-variable-name">keep</span> = np.isfinite(cont_covars[j].values)
      result.append([i, j, np.square(st.pearsonr(pcs[i][keep], cont_covars[j][keep]))[0]])
  <span class="org-keyword">return</span> pd.DataFrame(result, columns=[<span class="org-string">'pc'</span>, <span class="org-string">'covar'</span>, <span class="org-string">'corr'</span>])

<span class="org-keyword">def</span> <span class="org-function-name">categorical_r2</span>(loadings, annotations, key, name):
  <span class="org-variable-name">categories</span> = <span class="org-builtin">sorted</span>(annotations[key].unique())
  <span class="org-variable-name">onehot</span> = np.zeros((annotations.shape[0], <span class="org-builtin">len</span>(categories)), dtype=np.float32)
  onehot[np.arange(onehot.shape[0]), annotations[key].<span class="org-builtin">apply</span>(<span class="org-keyword">lambda</span> x: categories.index(x))] = 1
  <span class="org-variable-name">m</span> = sklm.LinearRegression(fit_intercept=<span class="org-constant">True</span>, copy_X=<span class="org-constant">True</span>).fit(onehot, loadings)
  <span class="org-keyword">return</span> pd.DataFrame({
      <span class="org-string">'pc'</span>: np.arange(10),
      <span class="org-string">'covar'</span>: name,
      <span class="org-string">'corr'</span>: 1 - np.square(loadings - m.predict(onehot)).<span class="org-builtin">sum</span>(axis=0) / np.square(loadings - loadings.mean(axis=0)).<span class="org-builtin">sum</span>(axis=0)})
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython" id="org27d8282"><span class="org-variable-name">cont_covars</span> = annotations.<span class="org-builtin">apply</span>(extract_covars, axis=1)
<span class="org-variable-name">cat_covars</span> = <span class="org-builtin">list</span>(<span class="org-builtin">zip</span>(annotations[[<span class="org-string">'batch'</span>, <span class="org-string">'experiment'</span>, <span class="org-string">'chip_id'</span>, <span class="org-string">'well'</span>]],
                      [<span class="org-string">'Batch'</span>, <span class="org-string">'C1 chip'</span>, <span class="org-string">'Individual'</span>, <span class="org-string">'Well'</span>]))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">corr</span> = pd.concat(
  [correlation(pd.DataFrame(loadings), cont_covars)] +
  [categorical_r2(loadings, annotations, k, n) <span class="org-keyword">for</span> k, n <span class="org-keyword">in</span> cat_covars])
<span class="org-variable-name">corr</span> = corr.pivot(index=<span class="org-string">'covar'</span>, columns=<span class="org-string">'pc'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython" id="org40adbe4"><span class="org-keyword">def</span> <span class="org-function-name">plot_pca_covar_corr</span>(pca, corr):
  plt.clf()
  <span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, gridspec_kw={<span class="org-string">'height_ratios'</span>: [.25, .75]}, sharex=<span class="org-constant">True</span>)
  fig.set_size_inches(4, 5)
  ax[0].bar(np.arange(<span class="org-builtin">len</span>(pca.components_)), pca.explained_variance_ratio_)
  ax[0].set_xticks(np.arange(<span class="org-builtin">len</span>(pca.components_)))
  ax[0].set_xticklabels([<span class="org-builtin">str</span>(x) <span class="org-keyword">for</span> x <span class="org-keyword">in</span> np.arange(1, <span class="org-builtin">len</span>(pca.components_) + 1)])
  ax[0].set_xlabel(<span class="org-string">'Principal component'</span>)
  ax[0].set_ylabel(<span class="org-string">'PVE'</span>)

  <span class="org-variable-name">im</span> = ax[1].imshow(corr.values, cmap=colorcet.cm[<span class="org-string">'fire'</span>], vmin=0, vmax=1, aspect=<span class="org-string">'auto'</span>)
  <span class="org-variable-name">cb</span> = plt.colorbar(im, ax=ax[1], orientation=<span class="org-string">'horizontal'</span>)
  cb.set_label(<span class="org-string">'Squared correlation'</span>)
  ax[1].set_xlabel(<span class="org-string">'Principal component'</span>)
  ax[1].set_yticks(np.arange(corr.shape[0]))
  ax[1].set_yticklabels(corr.index)
  ax[1].set_ylabel(<span class="org-string">'Covariate'</span>)

  plt.gcf().tight_layout()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'svg'</span>])
plot_pca_covar_corr(ppca, corr)
</pre>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="figure/dim-reduction.org/pca-vs-covars.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org7a286e5" class="outline-2">
<h2 id="org7a286e5">Effect of dropout on gene expression</h2>
<div class="outline-text-2" id="text-org7a286e5">
<p>
Hicks et al also claim that the entire distribution of non-zero measurements
depends on detection rate. They show this by plotting the percentiles of
non-zero expressed genes in each cell versus detection rate in that cell.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">plot_quantiles_vs_detection</span>(umi, annotations, quantiles=<span class="org-constant">None</span>, pseudocount=<span class="org-constant">None</span>):
  <span class="org-keyword">if</span> quantiles <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">quantiles</span> = np.linspace(0, 1, 5)
  <span class="org-keyword">else</span>:
    <span class="org-keyword">assert</span> (quantiles &gt;= 0).<span class="org-builtin">all</span>()
    <span class="org-keyword">assert</span> (quantiles &lt;= 1).<span class="org-builtin">all</span>()
  <span class="org-variable-name">vals</span> = np.nanpercentile(np.ma.masked_equal(umi.values, 0).astype(<span class="org-builtin">float</span>).filled(np.nan), 100 * quantiles, axis=0, interpolation=<span class="org-string">'higher'</span>)
  <span class="org-keyword">if</span> pseudocount <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-comment-delimiter"># </span><span class="org-comment">log CPM with per-cell pseudocount</span>
    <span class="org-variable-name">total_counts</span> = umi.<span class="org-builtin">sum</span>()
    <span class="org-variable-name">pseudocount</span> = .5 * total_counts / total_counts.mean()
    <span class="org-variable-name">label</span> = <span class="org-string">'log CPM'</span>
    <span class="org-variable-name">vals</span> = np.log(vals + pseudocount.values.reshape(1, -1)) - np.log(total_counts + 2 * pseudocount).values.reshape(1, -1) + 6 * np.log(10)
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">vals</span> = np.log(vals + pseudocount)
    <span class="org-variable-name">label</span> = <span class="org-string">'$\log({} + {:.3g})$'</span>.<span class="org-builtin">format</span>(<span class="org-string">'\mathrm{UMI}'</span>, pseudocount)

  plt.clf()
  plt.gcf().set_size_inches(4, 4)
  <span class="org-keyword">for</span> q, v <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(quantiles, vals):
    plt.scatter(annotations[<span class="org-string">'detect_hs'</span>] / keep_genes.shape[0], v, c=colorcet.cm[<span class="org-string">'inferno'</span>](q), label=<span class="org-string">'{:.2f}'</span>.<span class="org-builtin">format</span>(q), s=2)
  plt.legend(title=<span class="org-string">'Quantile'</span>, frameon=<span class="org-constant">False</span>, fancybox=<span class="org-constant">False</span>, bbox_to_anchor=(1, .5), loc=<span class="org-string">'center left'</span>)
  plt.xlabel(<span class="org-string">'Proportion of genes detected'</span>)
  plt.ylabel(label)
</pre>
</div>

<p>
We recapitulate the main result of Hicks et al in our data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
plot_quantiles_vs_detection(umi, annotations)
</pre>
</div>


<div class="figure">
<p><img src="figure/dim-reduction.org/umi-quantiles-vs-detection.png" alt="umi-quantiles-vs-detection.png">
</p>
</div>

<p>
log CPM as defined in <code>edgeR</code> uses a pseudocount which depends on library
size, but the derivation in Hicks et al is for \(\log(X + \epsilon)\) where
\(\epsilon\) is constant across cells. 
</p>

<p>
Using constant \(\epsilon\) changes the shape of the relationship between
quantiles of non-zero expression and detection rate, but does not remove the
relationship.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plot_quantiles_vs_detection(umi, annotations, pseudocount=1)
</pre>
</div>


<div class="figure">
<p><img src="figure/dim-reduction.org/umi-quantiles-vs-detection-1.png" alt="umi-quantiles-vs-detection-1.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plot_quantiles_vs_detection(umi, annotations, pseudocount=1e-3)
</pre>
</div>


<div class="figure">
<p><img src="figure/dim-reduction.org/umi-quantiles-vs-detection-1e-3.png" alt="umi-quantiles-vs-detection-1e-3.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org0bcc25a" class="outline-2">
<h2 id="org0bcc25a">PCA on bicentered data</h2>
<div class="outline-text-2" id="text-org0bcc25a">
<p>
Bi-center the data, by fitting a model where observations depend on a
row-mean and a column-mean and then subtracting the means from each entry.
</p>

<p>
\[ x_{ij} \sim N(u_i + v_j, \sigma^2) \]
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">sample_feature_means</span>(obs, max_iters=10):
  <span class="org-doc">"""Fit per-feature and per-sample means</span>

<span class="org-doc">  x_ij ~ N(u_i + v_j, sigma^2)</span>

<span class="org-doc">  Inputs:</span>

<span class="org-doc">  x - ndarray (num_samples, num_features)</span>

<span class="org-doc">  Returns:</span>
<span class="org-doc">  sample_means - ndarray (num_samples, 1)</span>
<span class="org-doc">  feature_means - ndarray (num_features, 1)</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = obs.shape
  <span class="org-variable-name">sample_means</span> = np.zeros((n, 1))
  <span class="org-variable-name">feature_means</span> = np.zeros((1, p))
  <span class="org-variable-name">resid</span> = obs.var()
  <span class="org-variable-name">llik</span> = -.5 * np.<span class="org-builtin">sum</span>(np.log(2 * np.pi * resid) + (obs - feature_means - sample_means) / resid)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Coordinate ascent on llik</span>
  <span class="org-keyword">for</span> _ <span class="org-keyword">in</span> <span class="org-builtin">range</span>(max_iters):
    <span class="org-variable-name">sample_means</span> = np.mean(obs - feature_means, axis=1, keepdims=<span class="org-constant">True</span>)
    <span class="org-variable-name">feature_means</span> = np.mean(obs - sample_means, axis=0, keepdims=<span class="org-constant">True</span>)
    <span class="org-comment-delimiter"># </span><span class="org-comment">By default, np divides by N, not N - 1</span>
    <span class="org-variable-name">resid</span> = np.var(obs - feature_means - sample_means)
    <span class="org-variable-name">update</span> = -.5 * np.<span class="org-builtin">sum</span>(np.log(2 * np.pi * resid) + (obs - feature_means - sample_means) / resid)
    <span class="org-keyword">print</span>(update)
    <span class="org-keyword">if</span> np.isclose(update, llik):
      <span class="org-keyword">return</span> sample_means, feature_means.T
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">llik</span> = update
  <span class="org-keyword">raise</span> <span class="org-type">ValueError</span>(<span class="org-string">"Failed to converge"</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">plot_bicentered_pca</span>(log_cpm, annotations, cont_covars, cat_covars):
  <span class="org-variable-name">sample_means</span>, <span class="org-variable-name">feature_means</span> = sample_feature_means(log_cpm.values.T)
  <span class="org-variable-name">ppca</span> = skd.PCA(n_components=10)
  <span class="org-variable-name">loadings</span> = ppca.fit_transform(log_cpm.values.T - sample_means - feature_means.T)
  <span class="org-variable-name">corr</span> = pd.concat(
    [correlation(pd.DataFrame(loadings), cont_covars)] +
    [categorical_r2(loadings, annotations, k, n) <span class="org-keyword">for</span> k, n <span class="org-keyword">in</span> cat_covars])
  <span class="org-variable-name">corr</span> = corr.pivot(index=<span class="org-string">'covar'</span>, columns=<span class="org-string">'pc'</span>)
  plot_pca_covar_corr(ppca, corr)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'svg'</span>])
plot_bicentered_pca(log_cpm, annotations, cont_covars, cat_covars)
</pre>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="figure/dim-reduction.org/pca-bicentered-covars.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org248ec82" class="outline-2">
<h2 id="org248ec82">Kernel PCA</h2>
<div class="outline-text-2" id="text-org248ec82">
<p>
The dependency of non-zero gene expression on gene detection rate is
non-linear, so use kernel PCA to perform non-linear dimensionality reduction
(<a href="https://www.mitpressjournals.org/doi/10.1162/089976698300017467">Sch√∂lkopf et al 1998</a>). The basic idea is to non-linearly map the original
points into a different space, and perform PCA in that space.
</p>

<p>
The method eliminates the second technical PC by accurately modeling the
non-linearity in the data, but it fails to eliminate the first technical PC
because it does not include sample-specific mean parameters. 
</p>

<p>
It is non-trivial to add such parameters because we have to center the
projections of the samples, and the key algorithmic trick used is that we
never have to actually compute the projections. In particular, we assume the
radial basis function kernel, which projects the data into infinite
dimensional space, making it impossible to compute the projections.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">kpca</span> = skd.KernelPCA(kernel=<span class="org-string">'rbf'</span>, n_components=10)
<span class="org-variable-name">loadings_kpca</span> = kpca.fit_transform(log_cpm.values.T)
<span class="org-variable-name">corr_kpca</span> = pd.concat(
  [correlation(pd.DataFrame(loadings_kpca), cont_covars)] +
  [categorical_r2(loadings_kpca, annotations, k, n) <span class="org-keyword">for</span> k, n <span class="org-keyword">in</span> cat_covars])
<span class="org-variable-name">corr_kpca</span> = corr_kpca.pivot(index=<span class="org-string">'covar'</span>, columns=<span class="org-string">'pc'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython" id="org026aff3">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'svg'</span>])
plt.clf()
plt.gcf().set_size_inches(8, 12)
<span class="org-variable-name">im</span> = plt.imshow(corr_kpca.values, cmap=colorcet.cm[<span class="org-string">'fire'</span>], vmin=0, vmax=1, aspect=<span class="org-string">'auto'</span>)
<span class="org-variable-name">cb</span> = plt.colorbar(im, orientation=<span class="org-string">'horizontal'</span>)
cb.set_label(<span class="org-string">'Squared correlation'</span>)
plt.gca().set_xlabel(<span class="org-string">'Principal component'</span>)
plt.gca().set_yticks(np.arange(corr_kpca.shape[0]))
plt.gca().set_yticklabels(corr_kpca.index)
plt.gca().set_ylabel(<span class="org-string">'Covariate'</span>)
plt.gcf().tight_layout()
</pre>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="figure/dim-reduction.org/kpca-covars.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>

<pre class="example">
Text(0,0.5,'Covariate')

</pre>

<div class="figure">
<p><img src="figure/dim-reduction.org/kpca-covars.png" alt="kpca-covars.png">
</p>
</div>
</div>
</div>

<div id="outline-container-orgbdbc407" class="outline-2">
<h2 id="orgbdbc407">PCA on gene expression residuals</h2>
<div class="outline-text-2" id="text-orgbdbc407">
<p>
Although the dependency of the percentiles of non-zero gene expression on
detection rate appears to be nonlinear, we can partially correct for it by
regressing out the percentiles of expression from the expression values for
each gene.
</p>

<p>
\[ y_{ij} = p_i \beta + \mu_j + \epsilon_{ij} \]
</p>

<p>
\[ \tilde{y}_{ij} = y_{ij} - p_i \hat\beta - \hat\mu_j \]
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">normalized_percentiles</span> = np.percentile(log_cpm, 100 * np.linspace(0, 1, 5), axis=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">log_cpm_residuals</span> = log_cpm.<span class="org-builtin">apply</span>(<span class="org-keyword">lambda</span> y: y - sklm.LinearRegression(fit_intercept=<span class="org-constant">True</span>).fit(normalized_percentiles.T, y).predict(normalized_percentiles.T), axis=1)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'svg'</span>])
plot_bicentered_pca(log_cpm_residuals, annotations, cont_covars, cat_covars)
</pre>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="figure/dim-reduction.org/pca-expr-residual-covars.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>

<div id="outline-container-org013192f" class="outline-2">
<h2 id="org013192f">PCA on quantile-normalized log CPM</h2>
<div class="outline-text-2" id="text-org013192f">
<p>
Regression against the percentiles of gene expression seems like an inelegant
way of performing quantile normalization. However, quantile normalizing
doesn't work.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> rpy2.robjects
<span class="org-keyword">import</span> rpy2.robjects.numpy2ri

<span class="org-variable-name">numpy2ri</span> = rpy2.robjects.numpy2ri.numpy2ri

<span class="org-keyword">def</span> <span class="org-function-name">qqnorm</span>(x):
  <span class="org-doc">"""Wrap around R qqnorm"""</span>
  <span class="org-keyword">return</span> np.asarray(rpy2.robjects.r[<span class="org-string">'qqnorm'</span>](numpy2ri(x))[0])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">normed</span> = log_cpm.<span class="org-builtin">apply</span>(qqnorm, axis=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'svg'</span>])
plot_bicentered_pca(normed, annotations, cont_covars, cat_covars)
</pre>
</div>


<div class="figure">
<p><object type="image/svg+xml" data="figure/dim-reduction.org/pca-qqnorm-covars.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2018-05-29 Tue 15:05</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
